{% macro conv_unit(
  input_name, unit_name,
  lr_w=1, lr_b=2, wd_w=1, wd_b=0,
  channels=64, kernel=5, stride=none, group=none, pad=none,
  w_filler={"type": '"gaussian"', "std": 0.01},
  b_filler={"type": '"constant"', "value": 0},
  param_name=none,
  pool_kernel=3, pool_stride=2,
  nonlin_type='ReLU', no_pool=false, no_norm=false)
%}
{% set conv_name = unit_name %}
{% set nonlin_name = unit_name + '-nonlin' %}
{% set pool_name = unit_name + '-pool' %}
{% set norm_name = unit_name + '-norm' %}
layer {
  name: "{{ conv_name }}"
  type: "Convolution"
  bottom: "{{ input_name }}"
  top: "{{ conv_name }}"
  param {
    lr_mult: {{ lr_w }}
    decay_mult: {{ wd_w }}
    {% if param_name is not none %}name: "{{ param_name }}_w"{%endif%}
  }
  param {
    lr_mult: {{ lr_b }}
    decay_mult: {{ wd_b }}
    {% if param_name is not none %}name: "{{ param_name }}_b"{%endif%}
  }
  convolution_param {
    num_output: {{ channels }}
    kernel_size: {{ kernel }}
    {% if stride is not none %}stride: {{ stride }}{% endif %}
    {% if group is not none %}group: {{ group }}{% endif %}
    {% if pad is not none %}pad: {{ pad }}{% endif %}
    weight_filler {
      {% for key, val in w_filler.iteritems() %}{{ key }}: {{ val }}
      {% endfor %}
    }
    bias_filler {
      {% for key, val in b_filler.iteritems() %}{{ key }}: {{ val }}
      {% endfor %}
    }
  }
}
{% if nonlin_type is not none %}
layer {
  name: "{{ nonlin_name }}"
  type: "{{nonlin_type}}"
  bottom: "{{ conv_name }}"
  top: "{{ conv_name }}"
}
{% endif %}
{% if not no_pool %}
layer {
  name: "{{ pool_name }}"
  type: "Pooling"
  bottom: "{{ conv_name }}"
  top: "{{ pool_name }}"
  pooling_param {
    pool: MAX
    kernel_size: {{ pool_kernel }}
    stride: {{ pool_stride }}
  }
}
{% endif %}
{% if not no_norm %}
layer {
  name: "{{ norm_name }}"
  type: "LRN"
  bottom: "{{ pool_name }}"
  top: "{{ norm_name }}"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
{% endif %}
{% endmacro %}